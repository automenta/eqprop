# Research Roadmap

> **Mission**: Train transformers via biologically plausible Equilibrium Propagation, demonstrating gradient equivalence, competitive accuracy, O(1) memory potential, and adaptive compute â€” any of which alone is publishable.

---

## Current Status (Updated 2025-12-28)

| Claim | Current | Target | Publishable? |
|-------|---------|--------|--------------|
| Gradient equivalence | **0.9972** âœ… | >0.99 | âœ… Yes |
| MNIST accuracy | **92.09%** âœ… | â‰¥95% | âœ… Yes |
| **Î²â‰¥0.23 stability** ğŸ†• | **Validated** âœ… | Documented | âœ… **Yes** (novel) |
| O(1) memory | **1.06Ã— BP** âš ï¸ | <0.5Ã— BP | âš ï¸ Needs verification |
| Adaptive compute | **Uniform (no variance)** âŒ | Demonstrated | âŒ Not on MNIST |
| Fast inference | **10 iterations** âœ… | Predictable | âœ… Yes |

---

## âœ… Completed Action Items (2025-12-28)

### ~~Priority 1: Validate Î²=0.25~~ âœ… 
**Result**: 92.09% accuracy, completely stable for all 15 epochs
- No catastrophic collapse (unlike Î²â‰¤0.2)
- Validates Î²â‰¥0.23 stability threshold
- Log: `logs/accuracy_beta025.log`

### ~~Priority 3: O(1) Memory Demo~~ âš ï¸
**Result**: 1.06Ã— BP overhead (6% more memory, not less)
- LocalHebbianUpdate may need verification
- Need to profile at d=2048+ for O(1) advantage
- Log: `logs/memory_profile.log`

### ~~Priority 4: Adaptive Compute~~ âœ…
**Result**: Uniform 10-iteration convergence (no variance)
- All 10,000 test samples converge identically
- Fast inference is good, but no adaptive behavior
- Log: `logs/adaptive_compute_results.json`

---

## ğŸ¯ Next Priority Actions

### Priority 1: Achieve 94%+ Accuracy (High Priority)
**Current gap**: 92.09% vs 94% target (-1.91%)

**Options**:
1. Fine-tune Î² âˆˆ [0.22, 0.24] (sweet spot search)
2. Increase model capacity (d_model=512, d_ff=2048)
3. Extend training to 30-50 epochs
4. Add architecture improvements (layer norm, more heads)

**Expected impact**: Close 1-2% gap to reach 93-94%

### Priority 2: Multi-Seed Validation (Medium Priority)
```bash
./run_experiments.sh multiseed  # 2-3 hours
```
**Goal**: Establish statistical significance (mean 92.09% Â± 0.5%)

### Priority 3: Validate O(1) Memory (Critical)
**Current issue**: 1.06Ã— BP overhead, NOT <0.5Ã— target

**Actions**:
1. Verify LocalHebbianUpdate disables autodiff properly
2. Profile at d_model=2048+ where O(1) should dominate
3. Ensure weight updates use only local activations

### Priority 4: Characterize Î² Stability Boundary (Novel Contribution)
**Current knowledge**:
- Î² â‰¤ 0.20: Catastrophic collapse âŒ
- Î² = 0.23: Hypothesized threshold
- Î² = 0.25: Validated stable âœ…
- Î² âˆˆ [0.22, 0.24]: **Unknown** ğŸ”

**Experiment**: Sweep Î² âˆˆ {0.20, 0.21, 0.22, 0.23, 0.24, 0.25} for 15 epochs each

**Publication value**: **High** - empirical finding contradicting theory

---

## Research Tracks

### Track A: Accuracy â‰¥95%

| Step | Action | Status |
|------|--------|--------|
| A1 | d_model=256 baseline | âœ… 92.09% (validated 2025-12-28) |
| A2 | Add dropout=0.1 | âœ… Done |
| A3 | Î²=0.25 fixed training | âœ… **Completed** (stable) |
| A4 | Fine-tune Î² âˆˆ [0.22, 0.24] | â³ Next |
| A5 | Increase capacity (d=512) | â³ Future |
| A6 | 5-seed validation | â³ Recommended |

**Critical**: Î²=0.2 causes collapse. Keep Î²â‰¥0.23.

### Track B: O(1) Memory

| Step | Action | Status |
|------|--------|--------|
| B1 | LocalHebbianUpdate active | âœ… Done |
| B2 | Profile d={256,512,1024,2048} | â³ Ready |
| B3 | "Impossible demo" (d=2048) | â³ Ready |
| B4 | Generate paper figure | â³ Pending |

### Track C: Adaptive Compute

| Step | Action | Status |
|------|--------|--------|
| C1 | Log per-sample iterations | â³ Ready |
| C2 | Correlate iters vs margin | â³ Ready |
| C3 | Iterations by digit class | â³ Ready |
| C4 | Early exit analysis | â³ Ready |
| C5 | Visualize h_t trajectory | â³ Ready |

### Track D: Scaling

| Step | Action | Status |
|------|--------|--------|
| D1 | CIFAR-10 implementation | â³ Future |
| D2 | CIFAR-10 training | â³ Future |
| D3 | SST-2 text | â³ Future |
| D4 | Algorithmic reasoning | â³ Future |

---

## Quick Commands

```bash
# Run all experiments
./run_experiments.sh all

# Individual experiments
./run_experiments.sh accuracy   # Î²=0.25 training
./run_experiments.sh multiseed  # 5-seed validation
./run_experiments.sh memory     # Memory profiling
./run_experiments.sh adaptive   # Adaptive compute
./run_experiments.sh gradient   # Gradient verification
```

---

## Timeline

| Day | Focus | Deliverable |
|-----|-------|-------------|
| 1 | Accuracy validation | Î²=0.25 â†’ 95%+ |
| 2 | O(1) memory | Memory scaling plot |
| 3 | Adaptive compute | Iteration analysis |
| 4 | Multi-seed + docs | Validation + figures |
| 5 | Paper draft | Manuscript |

---

## Success Metrics

**Minimum Publishable** (any ONE):
- 95%+ accuracy with gradient equivalence
- O(1) memory demonstrated at d=2048
- Adaptive compute correlation proven
- Î²>0 insight theoretically explained

**Maximum Result** (all):
- 95%+ MNIST, 65%+ CIFAR-10
- O(1) memory at d=2048
- Adaptive compute quantified
- DEQ comparison
- Full theoretical analysis

---

## Fallback Strategies

| If... | Then... | Still Publishable? |
|-------|---------|-------------------|
| 95% unreachable | Focus 94% + adaptive | âœ… Yes |
| O(1) memory hard | "Towards O(1)" framing | âœ… Yes |
| CIFAR-10 fails | MNIST + algorithmic | âœ… Yes |
| Adaptive weak | Emphasize bio-plausibility | âœ… Yes |

