"""
Temporal Resonance: Spatiotemporal Limit Cycle Dynamics (Track 7)

Limits cycles allow "infinite context window" by resonating with input sequences
rather than buffering them.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from typing import Tuple, List, Dict, Optional
from torch.nn.utils.parametrizations import spectral_norm
from .utils import spectral_linear

class TemporalResonanceEqProp(nn.Module):
    """
    EqProp network that converges to a stable oscillation (limit cycle)
    instead of a fixed point.
    """
    
    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,
                 num_layers: int = 3, alpha: float = 0.5,
                 oscillation_strength: float = 0.1,
                 use_spectral_norm: bool = True):
        super().__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.alpha = alpha
        self.oscillation_strength = oscillation_strength
        
        # Input projection
        self.W_in = nn.Linear(input_dim, hidden_dim)
        
        # Recurrent layers
        self.layers = nn.ModuleList([
            spectral_linear(hidden_dim, hidden_dim, use_sn=use_spectral_norm)
            for _ in range(num_layers)
        ])
        
        # Oscillatory coupling (creates limit cycles)
        self.osc_coupling = nn.Linear(hidden_dim, hidden_dim, bias=False)
        if use_spectral_norm:
            self.osc_coupling = spectral_norm(self.osc_coupling)
            
        # Output head
        self.head = nn.Linear(hidden_dim, output_dim)
        
        # Initialize for stable oscillations
        self._init_oscillatory_weights()
    
    def _init_oscillatory_weights(self):
        """Initialize oscillatory coupling for stable limit cycles."""
        with torch.no_grad():
            dim = self.hidden_dim
            self.osc_coupling.weight.zero_()
            
            # Block-diagonal rotation blocks
            for i in range(0, dim - 1, 2):
                angle = 0.1  # Small rotation angle
                c, s = math.cos(angle), math.sin(angle)
                self.osc_coupling.weight[i, i] = c
                self.osc_coupling.weight[i, i+1] = -s
                self.osc_coupling.weight[i+1, i] = s
                self.osc_coupling.weight[i+1, i+1] = c
            
            self.osc_coupling.weight.mul_(self.oscillation_strength)
    
    def forward_step(self, h: torch.Tensor, x: torch.Tensor) -> torch.Tensor:
        """Single integration step."""
        x_emb = self.W_in(x)
        
        # Standard recurrent dynamics
        h_recurrent = x_emb
        for layer in self.layers:
            h_recurrent = h_recurrent + layer(torch.tanh(h))
        
        # Oscillatory contribution
        h_oscillatory = self.osc_coupling(h)
        
        # Combined target
        h_target = torch.tanh(h_recurrent + h_oscillatory)
        
        # Euler integration step
        return (1 - self.alpha) * h + self.alpha * h_target
    
    def forward(self, x: torch.Tensor, steps: int = 30) -> torch.Tensor:
        """Forward pass for single input."""
        batch_size = x.size(0)
        h = torch.zeros(batch_size, self.hidden_dim, device=x.device)
        
        for _ in range(steps):
            h = self.forward_step(h, x)
        
        return self.head(h)
    
    def forward_sequence(self, x_seq: torch.Tensor, 
                          steps_per_frame: int = 5) -> Tuple[torch.Tensor, List[torch.Tensor]]:
        """Process a sequence with resonant dynamics."""
        batch_size, seq_len, _ = x_seq.shape
        h = torch.zeros(batch_size, self.hidden_dim, device=x_seq.device)
        
        outputs = []
        trajectories = []
        
        for t in range(seq_len):
            x_t = x_seq[:, t, :]
            for _ in range(steps_per_frame):
                h = self.forward_step(h, x_t)
            
            trajectories.append(h.detach().clone())
            outputs.append(self.head(h))
        
        outputs = torch.stack(outputs, dim=1)
        return outputs, trajectories

    def detect_limit_cycle(self, x: torch.Tensor, max_steps: int = 200,
                            cycle_detection_window: int = 20) -> Dict:
        """Detect limit cycle properties."""
        batch_size = x.size(0)
        h = torch.zeros(batch_size, self.hidden_dim, device=x.device)
        trajectory = []
        
        for _ in range(max_steps):
            h = self.forward_step(h, x)
            trajectory.append(h.detach().clone())
        
        trajectory = torch.stack(trajectory) # [T, B, H]
        recent = trajectory[-cycle_detection_window:]
        
        # Auto-correlation analysis
        correlations = []
        for lag in range(1, cycle_detection_window // 2):
            corr = F.cosine_similarity(
                recent[:-lag].flatten(1),
                recent[lag:].flatten(1)
            ).mean().item()
            correlations.append(corr)
            
        if correlations:
            max_corr = max(correlations)
            cycle_length = correlations.index(max_corr) + 1
            cycle_detected = max_corr > 0.9
        else:
            max_corr, cycle_length, cycle_detected = 0, 0, False
            
        amplitude = torch.std(recent, dim=0).mean().item()
        
        return {
            'cycle_detected': cycle_detected,
            'cycle_length': cycle_length,
            'max_correlation': max_corr,
            'amplitude': amplitude
        }
