# TorEqProp Verification Results

**Generated**: 2026-01-04 22:50:29


## Executive Summary

**Verification completed in 1.6 seconds.**

### Overall Results

| Metric | Value |
|--------|-------|
| Tracks Verified | 3 |
| Passed | 3 ‚úÖ |
| Partial | 0 ‚ö†Ô∏è |
| Failed | 0 ‚ùå |
| Stubs (TODO) | 0 üîß |
| Average Score | 100.0/100 |

### Track Summary

| # | Track | Status | Score | Time |
|---|-------|--------|-------|------|
| 1 | Spectral Normalization Stability | ‚úÖ | 100 | 1.5s |
| 2 | EqProp vs Backprop Parity | ‚úÖ | 100 | 0.2s |
| 22 | Golden Reference Harness | ‚úÖ | 100 | 0.0s |


**Seed**: 42 (deterministic)

**Reproducibility**: All experiments use fixed seeds for exact reproduction.

---


## Track 1: Spectral Normalization Stability


‚úÖ **Status**: PASS | **Score**: 100.0/100 | **Time**: 1.5s


**Claim**: Spectral normalization constrains Lipschitz constant L ‚â§ 1, unlike unconstrained training.

**Experiment**: Train identical networks with and without spectral normalization.

| Configuration | L (before) | L (after) | Œî | Constrained? |
|---------------|------------|-----------|---|--------------|
| Without SN | 0.978 | 7.371 | +6.39 | ‚ùå No |
| With SN | 1.002 | 1.000 | -0.00 | ‚úÖ Yes |

**Key Difference**: L(no_sn) - L(sn) = 6.371

**Interpretation**: 
- Without SN: L = 7.37 (unconstrained, can grow)
- With SN: L = 1.00 (constrained to ~1.0)
- SN provides 637% reduction in Lipschitz constant




## Track 2: EqProp vs Backprop Parity


‚úÖ **Status**: PASS | **Score**: 100.0/100 | **Time**: 0.2s


**Claim**: EqProp achieves competitive accuracy with Backpropagation (gap < 3%).

**Experiment**: Train identical architectures with Backprop and EqProp on synthetic classification.

| Method | Test Accuracy | Gap |
|--------|---------------|-----|
| Backprop MLP | 12.5% | ‚Äî |
| EqProp (LoopedMLP) | 10.0% | +2.5% |

**Verdict**: ‚úÖ PARITY ACHIEVED (gap = 2.5%)

**Note**: Small datasets may show variance; run with --full for 5-seed validation.




### Areas for Improvement

- Low absolute accuracy; increase epochs or model size


## Track 22: Golden Reference Harness


‚úÖ **Status**: PASS | **Score**: 100.0/100 | **Time**: 0.0s


**Claim**: NumPy kernel matches PyTorch autograd to within numerical tolerance.

**Experiment**: Compare hidden states at each relaxation step.

| Metric | Value | Threshold |
|--------|-------|-----------|
| Max Hidden Diff | 1.79e-07 | < 1.00e-05 |
| Output Diff | 1.19e-07 | < 1.00e-05 |
| Steps Compared | 30 | - |

**Step-by-Step Comparison** (first/last steps):

| Step | Max Difference |
|------|----------------|
| 0 | 5.96e-08 |
| 1 | 1.19e-07 |
| 2 | 1.19e-07 |
| 3 | 1.49e-07 |
| 4 | 1.19e-07 |
| 28 | 1.79e-07 |
| 29 | 1.19e-07 |

**Purpose**: This harness enables safe optimization of the engine. Any new kernel
implementation must pass this test before deployment.

**Status**: ‚úÖ VALIDATED - Safe to optimize


